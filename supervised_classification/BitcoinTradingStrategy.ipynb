{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import talib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv, set_option\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_bitstamp_data(symbol, start, end, timeframe, limit=1000):\n",
    "    url = f\"https://www.bitstamp.net/api/v2/ohlc/{symbol}/\"\n",
    "    data_frames = []\n",
    "    \n",
    "    while start < end:\n",
    "        # Ajustar end para la solicitud actual para no exceder el límite de 1000 registros\n",
    "        current_end = min(start + (timeframe * limit), end)\n",
    "        # Debug\n",
    "        #print(f\"{pd.to_datetime(start, unit='s')} - {pd.to_datetime(current_end, unit='s')}\")\n",
    "        params = {\n",
    "            'start': int(start),\n",
    "            'end': int(current_end),\n",
    "            'step': timeframe,\n",
    "            'limit': limit,\n",
    "            'exclude_current_candle': False\n",
    "        }\n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                df = pd.DataFrame(data['data']['ohlc'])\n",
    "                if not df.empty:\n",
    "                    data_frames.append(df)\n",
    "            else:\n",
    "                raise Exception(f\"Failed to fetch data: {response.status_code}, {response.text}\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "\n",
    "        start = current_end\n",
    "    # Combinar todos los DataFrames\n",
    "    if data_frames:\n",
    "        df = pd.concat(data_frames, ignore_index=True)\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "        df = df.set_index('timestamp')\n",
    "        df = df.sort_index()\n",
    "        df.index.name = 'date'\n",
    "        df = df.astype({\n",
    "            'open': float,\n",
    "            'high': float,\n",
    "            'low': float,\n",
    "            'close': float,\n",
    "            'volume': float\n",
    "        })\n",
    "        return df\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Uso de ejemplo\n",
    "start_date = pd.Timestamp('2011-01-01').timestamp()\n",
    "end_date = pd.Timestamp.now(tz='UTC').timestamp()\n",
    "\n",
    "df = fetch_bitstamp_data('btcusd', start=start_date, end=end_date, timeframe=3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis exploratorio de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingeniería de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear indicadores técnicos\n",
    "df['short_mavg'] = talib.SMA(real=df['close'], timeperiod=10)\n",
    "df['long_mavg'] = talib.SMA(real=df['close'], timeperiod=60)\n",
    "df['ema10'] = talib.EMA(real=df['close'], timeperiod=10)\n",
    "df['ema30'] = talib.EMA(real=df['close'], timeperiod=30)\n",
    "df['ema200'] = talib.EMA(real=df['close'], timeperiod=200)\n",
    "df['roc10'] = talib.ROC(real=df['close'], timeperiod=10)\n",
    "df['roc30'] = talib.ROC(real=df['close'], timeperiod=30)\n",
    "df['mom10'] = talib.MOM(real=df['close'], timeperiod=10)\n",
    "df['mom30'] = talib.MOM(real=df['close'], timeperiod=30)\n",
    "df['rsi10'] = talib.RSI(real=df['close'], timeperiod=10)\n",
    "df['rsi30'] = talib.RSI(real=df['close'], timeperiod=30)\n",
    "df['rsi200'] = talib.RSI(real=df['close'], timeperiod=200)\n",
    "df['k10'], df['d10'] = talib.STOCH(high=df['high'], low=df['low'], close=df['close'], fastk_period=10, slowk_period=10, slowd_period=10)\n",
    "df['k30'], df['d30'] = talib.STOCH(high=df['high'], low=df['low'], close=df['close'], fastk_period=30, slowk_period=30, slowd_period=30)\n",
    "df['k200'], df['d200'] = talib.STOCH(high=df['high'], low=df['low'], close=df['close'], fastk_period=200, slowk_period=200, slowd_period=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar valores nulos\n",
    "if df.isnull().values.any():\n",
    "    df = df.dropna()\n",
    "print(f'Null values = {df.isnull().values.any()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar la señal\n",
    "df['signal'] = np.where(df['short_mavg'] > df['long_mavg'], 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluir características innecesarias para la predicción\n",
    "df = df.drop(columns=['high', 'low', 'open', 'short_mavg', 'long_mavg'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['close']].plot(grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(sharex=False, sharey= False, xlabelsize=1, ylabelsize=1, figsize=(12, 12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['signal']).size().plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(df.corr(), vmax=1, square=True, annot=True, cmap='cubehelix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar algoritmos y modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test split\n",
    "Y = df['signal']\n",
    "X = df.loc[:, df.columns != 'signal']\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('AB', AdaBoostClassifier()))\n",
    "models.append(('GBM', GradientBoostingClassifier()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "#models.append(('SVM', SVC()))\n",
    "models.append(('XGB', XGBClassifier()))\n",
    "models.append(('LGBM', LGBMClassifier()))\n",
    "models.append(('CAT', CatBoostClassifier()))\n",
    "models.append(('SGD', SGDClassifier()))\n",
    "models.append(('BAG', BaggingClassifier()))\n",
    "models.append(('ET', ExtraTreesClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opciones\n",
    "num_folds = 10\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(f'{name}: {cv_results.mean()} ({cv_results.std()})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparar algoritmos\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Comparación de algoritmos')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "fig.set_size_inches(15, 8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_scaled = scaler.transform(X_train)\n",
    "# Parámetros a optimizar con grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "model = models[-1][1]\n",
    "kfold = KFold(n_splits=num_folds)\n",
    "grid = GridSearchCV(estimator=model, param_grid= param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result =grid.fit(X_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}')\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "ranks = grid_result.cv_results_['rank_test_score']\n",
    "for mean, stdev, param, rank in zip(means, stds, params, ranks):\n",
    "    print(f'#{rank} {mean} ({stdev}) with: {param}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados del modelo tuneado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExtraTreesClassifier(\n",
    "    n_estimators=params['n_estimators'],\n",
    "    max_features=params['max_features'],\n",
    "    max_depth=params['max_depth'],\n",
    "    min_samples_split=params['min_samples_split'],\n",
    "    min_samples_leaf=params['min_samples_leaf'],\n",
    "    criterion=params['criterion']\n",
    "    )\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultados en validation set\n",
    "y_pred = model.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, y_pred))\n",
    "print(confusion_matrix(Y_validation, y_pred))\n",
    "print(classification_report(Y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(confusion_matrix(Y_validation, y_pred), columns=np.unique(Y_validation), index=np.unique(Y_validation))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "sns.heatmap(df_cm, cmap='Blues', annot=True, annot_kws={'size': 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuición de variables / Importancia de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_importance = pd.DataFrame({'Importance': model.feature_importances_*100}, index=X.columns)\n",
    "features_importance.sort_values('Importance', axis=0, ascending=True).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtesting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una columna con los retornos de la estrategia multiplicando\n",
    "# la señal al cierre de la vela anterior por el retorno de la vela siguiente\n",
    "backtestdata = pd.DataFrame(index=X_validation.index)\n",
    "backtestdata['signal_pred'] = y_pred\n",
    "backtestdata['signal_actual'] = Y_validation\n",
    "backtestdata['Market Returns'] = X_validation['close'].pct_change()\n",
    "backtestdata['Actual Returns'] = backtestdata['Market Returns'] * backtestdata['signal_actual'].shift(1)\n",
    "backtestdata['Strategy Returns'] = backtestdata['Market Returns'] * backtestdata['signal_pred'].shift(1)\n",
    "backtestdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribución\n",
    "backtestdata[['Strategy Returns', 'Actual Returns']].cumsum().plot(kind='hist')\n",
    "backtestdata[['Strategy Returns', 'Actual Returns']].cumsum().plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
